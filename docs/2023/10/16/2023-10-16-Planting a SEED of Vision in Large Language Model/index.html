<!DOCTYPE html>
<html lang="en">
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="keyword"  content="">
    <link rel="shortcut icon" href="/blog/img/favicon.ico">

    <title>
        
        Planting a SEED of Vision in Large Language Model - undefined
        
    </title>

    <!-- Custom CSS -->
    
<link rel="stylesheet" href="/blog/css/aircloud.css">
<link rel="stylesheet" href="/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/.css" src="/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/.js">

    
<link rel="stylesheet" href="/blog/css/gitment.css">
<link rel="stylesheet" href="/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/.css" src="/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/.js">

    <!--<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">-->
    <link href="//at.alicdn.com/t/font_620856_pl6z7sid89qkt9.css" rel="stylesheet" type="text/css">
    <!-- ga & ba script hoook -->
    <script></script>
<meta name="generator" content="Hexo 5.4.0"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>

<body>

<!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="site-nav-toggle" id="site-nav-toggle">
    <button>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
    </button>
</div>

<div class="index-about">
    <i> 浙江大学可视分析小组博客 </i>
</div>

<div class="index-container">
    
    <div class="index-left">
        <div class="nav" id="nav">
    <div class="avatar-name">
        <div class="avatar ">
            <a href="/"><img
                    src="/img/avatar.png" /></a>
        </div>
        <div class="name">
            <a href="/">
                <i>ZJU VAI</i>
            </a>
        </div>
    </div>
    <div class="contents" id="nav-content">
        <ul>
            <li >
                <a
                    href="/">
                    <!-- <a href="/blog/about/"> -->
                    <!-- <i class="iconfont icon-fanhui"></i> -->
                    <span>🏠 小组主页</span>
                </a>
            </li>
            <li >
                <a href="/blog/">
                    <!-- <i class="iconfont icon-shouye1"></i> -->
                    <span>⌨️ 小组博客</span>
                </a>
            </li>
            <li >
                <a href="/blog/tags">
                    <!-- <i class="iconfont icon-biaoqian1"></i> -->
                    <span>📌 博客标签</span>
                </a>
            </li>
            <li >
                <a href="/blog/author">
                    <!-- <i class="iconfont icon-guanyu2"></i> -->
                    <span>👨‍🎓 作者存档</span>
                </a>
            </li>
            <li >
                <a href="/blog/archives">
                    <!-- <i class="iconfont icon-guidang2"></i> -->
                    <span>📅 时间存档</span>
                </a>
            </li>

            <li >
                <a href="/blog/textbook">
                    <!-- <i class="iconfont icon-biaoqian1"></i> -->
                    <span>📚 教材下载</span>
                </a>
            </li>
            
            <li>
                <a id="search">
                    <!-- <i class="iconfont icon-sousuo1"></i> -->
                    <span>🔎 博客搜索</span>
                </a>
            </li>
            

            <br />
            
            <li >
                <a target="_blank" rel="noopener" href="https://zjuvag.gitee.io/blog/">
                    <!-- <i class="iconfont icon-biaoqian2"></i> -->
                    <!-- <span style="color:#536589;font-weight:bold;">nav.mirror</span> -->
                </a>
            </li>
        </ul>
    </div>
    
    <div id="toc" class="toc-article">
    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%88%E5%89%8D%E5%B7%A5%E4%BD%9C"><span class="toc-text">先前工作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SEED"><span class="toc-text">SEED</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#SEED-%E8%AE%AD%E7%BB%83"><span class="toc-text">SEED 训练</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Tokenize"><span class="toc-text">Tokenize</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Visual-Quantization"><span class="toc-text">Visual Quantization</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#De-Tokenize"><span class="toc-text">De-Tokenize</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SEED-%E6%8E%A5%E5%85%A5-LLM"><span class="toc-text">SEED 接入 LLM</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Image-to-Text-Autoregression"><span class="toc-text">Image-to-Text Autoregression</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Image-to-Text-Autoregression-1"><span class="toc-text">Image-to-Text Autoregression</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%84%E4%BC%B0"><span class="toc-text">评估</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Causal-Embeddings-%E5%92%8C-Causal-Codes-%E5%AE%9A%E9%87%8F%E8%AF%84%E4%BC%B0"><span class="toc-text">Causal Embeddings 和 Causal Codes 定量评估</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Causal-Visual-Codes-%E9%87%8D%E6%9E%84%E8%83%BD%E5%8A%9B%E5%AE%9A%E6%80%A7%E8%AF%84%E4%BC%B0"><span class="toc-text">Causal Visual Codes 重构能力定性评估</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9B%BE%E7%89%87%E7%94%9F%E6%88%90%E8%83%BD%E5%8A%9B%E8%AF%84%E4%BC%B0"><span class="toc-text">图片生成能力评估</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%9A%E6%A8%A1%E6%80%81%E7%90%86%E8%A7%A3%E8%83%BD%E5%8A%9B%E8%AF%84%E4%BC%B0"><span class="toc-text">多模态理解能力评估</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA"><span class="toc-text">结论</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Reference"><span class="toc-text">Reference</span></a></li></ol></li></ol>
</div>
    
</div>


<div class="search-field" id="search-field">
    <div class="search-container">
        <div class="search-input">
            <span id="esc-search"> <i class="icon-fanhui iconfont"></i></span>
            <input id="search-input" />
            <span id="begin-search">搜索</span>
        </div>
        <div class="search-result-container" id="search-result-container">

        </div>
    </div>
</div>
        <div class="index-about-mobile">
            <i> 浙江大学可视分析小组博客 </i>
        </div>
    </div>
    
    <div class="index-middle">
        <!-- Main Content -->
        <div class="post-container">
    <div class="post-title">
        Planting a SEED of Vision in Large Language Model
    </div>

    <div class="post-meta">
        <!-- <span
            class="attr">发布于：<span>2023-10-16 00:00:00</span></span> -->
        <span class="attr">发布于：<span>2023-10-16</span></span>
        <span class="attr"><a class="tag" href="/blog/author/#沈健"
                title="沈健">沈健</a></span>
        
        <span class="attr">/
            
            <a class="tag" href="/blog/tags/#报告" title="报告">报告</a>
            <span>/</span>
            
            <a class="tag" href="/blog/tags/#论文评述" title="论文评述">论文评述</a>
            <span>/</span>
            
            
        </span>
        <span class="attr">访问：<span id="busuanzi_value_page_pv"></span>
        </span>
        </span>
    </div>
    <div class="post-content ">
        <p>论文：Planting a SEED of Vision in Large Language Model</p>
<p>作者：Yuying Ge, Yixiao Ge, Ziyun Zeng, Xintao Wang, Ying Shan</p>
<p>发表：arXiv</p>
<p>本文提出了图片词元化 SEED 模块，它能赋予大型语言模型同时查看和绘图的能力。在本研究中，作者确定了 SEED 架构和训练的两个关键原则，可有效简化后续与 LLM 的衔接。（1）图像词元化应该独立于 2D 物理块位置，而是通过 1D 因果依赖性生成，表现出与 LLM 中从左到右自回归预测机制一致的内在相互依赖性。（2）图像标记应捕获与单词语义抽象程度一致的高级语义，并在标记器训练阶段针对区分性和重建进行优化。因此，现成的 LLM 能够通过高效的 LoRA 微调，并结合 SEED 模块可以实现图像到文本和文本到图像的生成。此版本的 SEED 仅使用 64 个 V100 GPU 和 500 万个公开可用的图像文本对，在 5.7 天内完成了训练。本文的研究强调了离散视觉标记在多功能多模态 LLM 中的巨大潜力以及合适的图片词元化模块的重要性。</p>
<h2 id="先前工作"><a href="#先前工作" class="headerlink" title="先前工作"></a>先前工作</h2><p>最近的研究进一步利用 LLM 的强大通用性来提高视觉理解或生成任务，统称为多模态 LLM （MLLM）。</p>
<p>BLIP 处理图片为 token 作为上下文，从而回答用户提出的问题。GILL 通过将其输出嵌入空间与预训练的 SD 模型对齐，赋予 LLM 图像生成能力。这两个任务在处理过程中有很大的相似度。在此基础上，存在将这两个任务进一步融合到一个框架内的可能性。</p>
<p>因此，作者做了一个大胆的假设，多模态能力出现的前提是文本和图像可以在统一的自回归 Transformer 中互换表示和处理。</p>
<h2 id="SEED"><a href="#SEED" class="headerlink" title="SEED"></a>SEED</h2><p>提出的 SEED 是一种基于 VQVAE 的图像分词器，基于原图片生成具有一维因果依赖性的离散视觉码，这个离散视觉码具备视觉理解和生成任务所需的高级语义。该一维特征向量与 SD 的嵌入空间是对齐的，从而能够直接调用 SD decoder 生成图片。将第一步学习到的离散视觉标记视为新单词，并更新 LLM 的词汇表，再进行一定程度的微调，使得 LLM 理解这些新词汇。这样的做法可以让现有的 LLM 都能轻松兼容 SEED。</p>
<p>训练范式可以概括为三个阶段：视觉词元化模块训练、多模态预训练和多模态指令调整。虽然现有研究主要强调多模式训练（后两个阶段），但这项工作更关注视觉分词器（第一阶段）。</p>
<p>优秀的视觉分词器可以通过:简化视觉和单词标记之间的语义对齐，以及为多模态数据启用LLM的原始训练方法（即下一个词预测）来促进后续多模态训练，而无需针对视觉标记。将图像表示为一系列离散 ID 自然与 LLM 的自回归训练目标兼容。</p>
<p><img src="https://gcore.jsdelivr.net/gh/silent-shen/Online_Image/202312292053133.png" alt="image-20231229203330889" style="zoom: 67%;" /></p>
<h3 id="SEED-训练"><a href="#SEED-训练" class="headerlink" title="SEED 训练"></a>SEED 训练</h3><p>模型包含 5 个组件，其中的 ViT 编码器和 UNet 解码器直接源自预训练的 BLIP-2 和 SD 模型，不参与训练。其余三个部分的参数都需要训练。训练过程可以分为以下三步。</p>
<h4 id="Tokenize"><a href="#Tokenize" class="headerlink" title="Tokenize"></a>Tokenize</h4><p>该步目的是将图像表示为一系列离散Token。</p>
<p>使用来自 CC3M , Unsplash 和 COCO 数据集的 5M 图文对训练数据，基于图文对比损失优化 Causal Q-Former。对比损失函数中的正样本为图和图像的标题，负样本为同一个 batch 中的其他样本的标题。最大化正样本相似度，最小化负样本相似度。</p>
<p><img src="https://gcore.jsdelivr.net/gh/silent-shen/Online_Image/202312292053519.png" alt="image-20231229203348747" style="zoom:80%;" /></p>
<h4 id="Visual-Quantization"><a href="#Visual-Quantization" class="headerlink" title="Visual Quantization"></a>Visual Quantization</h4><p>VQ Codebook 将每个 causal embedding 转换为离散的量化的 causal code。做法是在 Codebook 中查找每个 causal embedding 的最近邻并获得相应的 causal code。</p>
<p>codebook 训练：使用一个多层 Transformer 解码器，从离散的 causal code 重构连续的 causal embedding。目标函数是，最大化重构 causal embedding 和真实 causal embedding 之间的余弦相似度。</p>
<h4 id="De-Tokenize"><a href="#De-Tokenize" class="headerlink" title="De-Tokenize"></a>De-Tokenize</h4><p>之前步骤得到了一串 code 包含了图片的信息，相当于一串没有实际意义的软文本，Reverse Q-Former 将学习到的 causal code 作为 cross attention 的 K V 输入，将 LQ 投影到 SD 的 Latent Space。最小化生成嵌入和 SD 文本特征之间的 MSE 损失。生成的嵌入可以输入 SD-UNet 来解码真实图像。</p>
<h3 id="SEED-接入-LLM"><a href="#SEED-接入-LLM" class="headerlink" title="SEED 接入 LLM"></a>SEED 接入 LLM</h3><p>训练好的 SEED 模块可以接入 LLM，可以是任意架构的 LLM，文中以 Decoder-Only 架构的 OPT 模型为例。</p>
<p>该过程涉及到两个训练任务：</p>
<p><img src="https://gcore.jsdelivr.net/gh/silent-shen/Online_Image/202312292053532.png" alt="image-20231229204513211" style="zoom:80%;" /></p>
<h4 id="Image-to-Text-Autoregression"><a href="#Image-to-Text-Autoregression" class="headerlink" title="Image-to-Text Autoregression"></a>Image-to-Text Autoregression</h4><ul>
<li><p>将两个模态的数据都 token 化，图片使用 SEED ，文本使用 LLM。</p>
</li>
<li><p>将 causal codes 对其到 $\text{SEED-OPT}_{2.7B}$ 的嵌入空间。</p>
</li>
<li><p>使用 LoRA 微调 LLM，使 LLM 兼容新的词汇本。</p>
</li>
</ul>
<h4 id="Image-to-Text-Autoregression-1"><a href="#Image-to-Text-Autoregression-1" class="headerlink" title="Image-to-Text Autoregression"></a>Image-to-Text Autoregression</h4><ul>
<li><p>训练过程与上述任务相反。</p>
</li>
<li><p>训练过程不需要调用图片生成模型。</p>
</li>
</ul>
<h3 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h3><h4 id="Causal-Embeddings-和-Causal-Codes-定量评估"><a href="#Causal-Embeddings-和-Causal-Codes-定量评估" class="headerlink" title="Causal Embeddings 和 Causal Codes 定量评估"></a>Causal Embeddings 和 Causal Codes 定量评估</h4><ul>
<li><p>图文检索任务。</p>
</li>
<li><p>使用 BLIP-2 作为 Baseline。</p>
</li>
<li><p>COCO 和 Flickr30K 数据集。</p>
<p><img src="https://gcore.jsdelivr.net/gh/silent-shen/Online_Image/202312292053870.png" alt="image-20231229205252505" style="zoom:67%;" /></p>
</li>
</ul>
<h4 id="Causal-Visual-Codes-重构能力定性评估"><a href="#Causal-Visual-Codes-重构能力定性评估" class="headerlink" title="Causal Visual Codes 重构能力定性评估"></a>Causal Visual Codes 重构能力定性评估</h4><p><img src="https://gcore.jsdelivr.net/gh/silent-shen/Online_Image/202312292053071.png" alt="image-20231229204815428" style="zoom:80%;" /></p>
<h4 id="图片生成能力评估"><a href="#图片生成能力评估" class="headerlink" title="图片生成能力评估"></a>图片生成能力评估</h4><p>SEED 首先将输入图像离散化为因果代码（32 个标记），并从 Reverse Q-Former 获得生成嵌入（77 个标记），并将其馈送到 SD-UNet 中以重建图像。<br>baseline 模型为 GILL 和 SD 。图像是根据输入图像的相应标题生成的。</p>
<p>CLIP相似度作为语义一致性基准的评估指标。</p>
<p><img src="https://gcore.jsdelivr.net/gh/silent-shen/Online_Image/202312292053373.png" alt="image-20231229205110879" style="zoom: 80%;" /></p>
<p><img src="https://gcore.jsdelivr.net/gh/silent-shen/Online_Image/202312292053111.png" alt="image-20231229205135674" style="zoom: 80%;" /></p>
<h4 id="多模态理解能力评估"><a href="#多模态理解能力评估" class="headerlink" title="多模态理解能力评估"></a>多模态理解能力评估</h4><p><img src="https://cdn.nlark.com/yuque/0/2023/png/34436368/1703854875434-bb28fa5b-966d-4f42-9cbb-57f7e5234e03.png" alt="img" style="zoom:80%;" /></p>
<h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><ul>
<li>通过高效的 LoRA 调优，结合 SEED 模块，现成的 LLM 能够执行图像到文本和文本到图像的生成。</li>
<li>SEED 的训练过程仅使用 64 个 V100 GPU 基于 5M 个公开可用的图像-文本对，在 5.7 天内完成了训练。</li>
<li>缓解了 MLLM 中可能出现的灾难性遗忘问题。</li>
</ul>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>[1] <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2307.08041v2.pdf">https://arxiv.org/pdf/2307.08041v2.pdf</a><br>[2] <a target="_blank" rel="noopener" href="https://github.com/ailab-cvc/seed">https://github.com/ailab-cvc/seed</a><br>[3] <a target="_blank" rel="noopener" href="https://browse.arxiv.org/pdf/2301.12597v3.pdf">https://browse.arxiv.org/pdf/2301.12597v3.pdf</a><br>[4] <a target="_blank" rel="noopener" href="https://openreview.net/pdf?id=YicbFdNTTy">https://openreview.net/pdf?id=YicbFdNTTy</a><br>[5] <a target="_blank" rel="noopener" href="https://aclanthology.org/2022.acl-long.215/">https://aclanthology.org/2022.acl-long.215/</a></p>

        
        <br />
        <div id="comment-container">
        </div>
        <div id="disqus_thread"></div>
        <hr/>
        <div id="lv-container">
            Questions & Discussion：<a href="mailto:zjuvis@cad.zju.edu.cn"><code> ✉️ zjuvis@cad.zju.edu.cn </code> </a>
        </div>
        <hr/>
    </div>
</div>
    </div>
</div>

<footer class="footer">
    <ul class="list-inline text-center">
             
    </ul>
    
    <p>
        Created By <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a> Theme
        <a target="_blank" rel="noopener" href="https://github.com/aircloud/hexo-theme-aircloud">AirCloud</a>
    </p>
</footer>


<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdn.bootcdn.net/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<!-- <script src="/blog/js/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script> --><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>

<script>
    // We expose some of the variables needed by the front end
    window.hexo_search_path = "search.json"
    window.hexo_root = "/blog/"
    window.isPost = true
</script>
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>

<script src="/blog/js/index.js"></script>
<script href="/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/.css" src="/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/blog/.js"></script>

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




</html>
