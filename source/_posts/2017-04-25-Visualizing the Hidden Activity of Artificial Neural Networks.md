---
title: "Visualizing the Hidden Activity of Artificial Neural Networks"
tags: ["论文评述", "报告"]
date: 2017-04-25
author: 朱闽峰
mail: minfeng_zhu@zju.edu.cn
mathjax: true
---

论文: Visualizing the Hidden Activity of Artificial Neural Networks

作者: Paulo E. Rauber, Samuel G. Fadel, Alexandre X. Falc ˜ao, and Alexandru C. Telea

发表会议: VAST 2016

## 介绍

在机器学习中，模式分类任务主要是根据样子学习得到模型把高维向量进行分类。人工神经网络在模式分类任务获得了最先进的结果，然而神经网络对我们来说还是一个黑盒。深度神经网络可以看作是对原始的图片数据进行了高层次的抽象，将图片转换成另一种高维向量，一种高层次的数据表达。而这个数据表达的每一个维度正是由神经元构成的。本文使用降维方法探索了数据表达以及神经元之间的关系，从而帮助我们了解和改进人工神经网络。

## 基础知识

模式分类任务是将 m 维的高维向量分类到 d 个类，其中高维向量可以由一张图片的所有像素构成。机器学习的目的就是通过样本集学习得到一个分类函数 f，可以使用于这种分类任务。训练的过程就是在修正函数内部的参数，使其提升对数据的抽象能力和分类正确率。深度神经网络就是使用大量的神经元构成一个分类函数。由于参数比较多，使得模型的适应能力比较强，可以得到更好的数据表达。如下图所示，一个多层感知机包括输入层，隐藏层和输出层。每一个都由多个神经元构成，神经元可以接受前一层神经元的输出，经过运算之后输出一个值。所以深度神经网络的每一层我们都可以获得一个向量，这个向量的每个维度是由这一层的所有神经元构成的。本文中称这个向量为数据表达。

![](http://www.cad.zju.edu.cn/home/vagblog/wp-content/uploads/2017/04/Picture1.png)

## 数据与模型

本文使用了多层感知机（MLP）和卷积神经网络（CNN0）对于数据集 MNIST、SVHN 和 CIFAR-10 进行测试，这两个模型在 3 个数据集上也取得了不错的分类效果。

![](http://www.cad.zju.edu.cn/home/vagblog/wp-content/uploads/2017/04/Picture2.png)

## 任务

作者在本章中进行了两个任务：

任务 1：数据表达之间的关系。数据表达在神经网络的不同层由什么变化，神经网络在训练的过程中的数据表达有什么变化。

任务 2：神经元之间的关系。神经元对不同图片或者特征的敏感性是如何变化的。

## 案例分析

### 任务 1:数据表达之间的关系

#### 1.1 训练效果——MNIST 数据集

如下图所示，左边是未经过训练的感知机的结果，右边是经过训练后感知机的最后一层的输出。我们把神经网络隐藏层的最后一层的向量使用 tSNE 进行投影，下图是投影结果。人工神经网络在训练过程中不断抓取数字分类特征，提供一个更好的数据表达，同一个类的数据在不断接近聚合，不同类之间的距离在不断扩大。

![](http://www.cad.zju.edu.cn/home/vagblog/wp-content/uploads/2017/04/Picture3.png)

#### 1.2 可视反馈——SVHN 数据集

把经过训练的多层感知机最后一层的向量进行投影后，我们可以看到大部分数字被分成了两类。通过可视化交互我们发现，这是因为同一个数字的图片会有两张类型，白底黑字或者黑底白字。通过这个发现，作者把图片进行预先的处理，消除这个现象然后再进行训练。多层感知机可以有 3.96% 准确率的提升，卷积神经网络有 0.65%的提升。这可能是因为卷积神经网络本身就具有对这种现象的识别能力。

![](http://www.cad.zju.edu.cn/home/vagblog/wp-content/uploads/2017/04/Picture4.png)

#### 1.3 数据表达在网络层次中的变化——MNIST 数据集

为了展示数据表达再不同阶段下的变化，作者把同一个数据的不同位置用线连接起来，从头到尾用颜色从深到浅表示，还做了边绑定，展示了数据位置的变化。对于在 MNIST 上训练的多层感知机，我们可以看到这个数据表达在神经网络的四个隐藏层中变化不是很大，数据在低层网络的时候就有很好的分割。同时，每一个类的数据在不断得变紧凑，远离其他类。

![](http://www.cad.zju.edu.cn/home/vagblog/wp-content/uploads/2017/04/Picture5.png)

#### 1.4 迭代过程中数据表达的变化——MNIST

下图展示了 100 次训练过程中，神经网络最后一层的数据表达的变化。在前几次训练的时候，数据表达的变化非常大。从一开始的分布在中间，到后面分布到四周。不同类别的数据表达就分裂比较远。

![](http://www.cad.zju.edu.cn/home/vagblog/wp-content/uploads/2017/04/Picture6.png)

### 任务 2：神经元之间的关系

由于神经网络里的高维向量每个维度都是由神经元产生，作者采用 Pearson 相关系数计算神经元之间的相似度，然后使用（multidimensional scaling ）MDS 进行投影。

#### 2.1 判别能力变化——MNIST

左边一列显示了数据表达的投影，右边一列显示了神经元的投影。透明度表示对数字 8 的判别能力。我们可以看到，经过训练，对数字 8 判别能力较强的神经元都聚合在一起。

![](http://www.cad.zju.edu.cn/home/vagblog/wp-content/uploads/2017/04/Picture8.png)

#### 2.2 神经元与分类的关系——SVHN

左图神色表示神经元对那种数字的判别能力最高，透明度表示判别能力。神经元 460 的颜色表明，他对数字 3 的识别能力很高，我们可以进行深入分析。当有数字图片经过神经元时，我们可以得到这个神经元激活的数值，在右图中显示了每张图片经过神经元产生的激活数值。我们发现高亮的部分主要位于数字 3。这说明神经元 460 对于数字 3 比较敏感。

我们也可以看到有部分数字 5 数值比较高，因为他们和数字 3 很像。

![](http://www.cad.zju.edu.cn/home/vagblog/wp-content/uploads/2017/04/Picture9.png)

## 讨论与总结

作者使用降维的方法探索了深度神经网络中数据表达之间的关系和神经元之间的关系。尽管案例结果揭示了很多神经网络的变化过程，这样的降维算法仍然存在一定的局限性。比如数据量较大时，投影计算效率比较低，如果数据太多可能相互之间存在遮挡。本文只使用了 3 种数据集和两种神经网络，覆盖范围比较小，未来可以考虑加入更多的神经网络类型。数据和神经元之间的关系，很多程度上决定与投影的算法，以及投影的初值，这可能对于分析结果也有一定的影响。
